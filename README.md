# Data-Science-101

Bias-Variance Tradeoff

Bias-variance tradeoff is a key concept that helps us to overcome the problem of
overfitting and underfitting.

Mathematical motivation:
Imagine we have a model: ğ‘¦ = ğ‘“(ğ‘¥)+ ğœ– where ğ¸(ğœ–) = 0, ğ‘‰ğ‘ğ‘Ÿ(ğœ–) = ğœ1
f is approximated by some loss minimization technique - ğ‘“2
We can use ğ‘“2 to predict y for new data, ğ‘¦3 â‰ˆ ğ‘“2(ğ‘¥3) â‰¡ ğ‘“23
Some useful properties,
ğ¸(ğ‘¦) = ğ¸(ğ‘“ + ğœ–) = ğ¸(ğ‘“) + ğ¸(ğœ–) = ğ‘“
ğ‘‰ğ‘ğ‘Ÿ(ğ‘¦) = ğ‘‰ğ‘ğ‘Ÿ(ğ‘“ + ğœ–) = ğ‘‰ğ‘ğ‘Ÿ(ğœ–) = ğœ1
Since f is deterministic, ğ¸(ğ‘“) = ğ‘“
ğ‘‰ğ‘ğ‘Ÿ(ğ‘‹) = ğ¸(ğ‘‹1) âˆ’ ğ¸(ğ‘‹)1, ğ‘Ÿğ‘’ğ‘ğ‘Ÿğ‘Ÿğ‘ğ‘›ğ‘”ğ‘–ğ‘›ğ‘” ğ‘ğ‘›ğ‘‘ ğ‘¤ğ‘’ ğ‘”ğ‘’ğ‘¡ ğ¸(ğ‘‹1) = ğ‘‰ğ‘ğ‘Ÿ(ğ‘‹) + ğ¸(ğ‘‹)1
Prediction Error/ Generalization Error/ Mean Squared Error = ğ¸[@ğ‘¦3 âˆ’ ğ‘“23A]1
